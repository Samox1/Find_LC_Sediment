{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Find_LC_Sedimentation.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaTTQ6iSRVZx"
      },
      "source": [
        "# Find Liquid Crystal Sedimentation = ML Project\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Yr4xvQ4VcW_"
      },
      "source": [
        "This notebook walks you through training a custom object detection model using the Tensorflow Object Detection API and Tensorflow 2.\n",
        "\n",
        "The notebook is split into the following parts:\n",
        "* Install the Tensorflow Object Detection API\n",
        "* Prepare data for use with the OD API\n",
        "* Write custom training configuration\n",
        "* Train detector\n",
        "* Export model inference graph\n",
        "* Test trained model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNT9cI_ZSCla"
      },
      "source": [
        "## Installation\n",
        "\n",
        "Installing the Tensorflow Object Detection API became a lot easier with the relase of Tensorflow 2. The following few cells are all that is needed in order to install the OD API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrELJFMZ_wPf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTBYWlnKSD78"
      },
      "source": [
        "!pip install -U --pre tensorflow==\"2.5.0\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kpha2-F_SGBj"
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmr2UdV_SHuc"
      },
      "source": [
        "# Install the Object Detection API\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzXxTBXHSNqA"
      },
      "source": [
        "#run model builder test\n",
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz1sd2reSTxg"
      },
      "source": [
        "## Prepare data\n",
        "\n",
        "To train a robust model, you need a lot of pictures that vary greatly from each other. You can either take the pictures yourself or you can download them from the internet.\n",
        "\n",
        "After collecting the images you need to label them. For this I recommend using [LabelImg](https://github.com/tzutalin/labelImg) - an free, open source graphical image annotation tool.\n",
        "\n",
        "\n",
        "After labeling the images, split the data into a training and testing part and convert the xml label files to csv using the [xml_to_csv.py](https://github.com/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model/blob/master/xml_to_csv.py) script.\n",
        "\n",
        "I uploaded my Microcontroller Detection data-set on Kaggle. The below four cells are used to download and extract the data-set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs4KdOs7coyX"
      },
      "source": [
        "!python /content/drive/MyDrive/Find_LC_Sedimentation_ML-Project_SSI/generate_tfrecord.py --csv_input=/content/drive/MyDrive/Find_LC_Sedimentation_ML-Project_SSI/images/train_labels.csv --image_dir=/content/drive/MyDrive/Find_LC_Sedimentation_ML-Project_SSI/images/train --output_path=train.record\n",
        "!python /content/drive/MyDrive/Find_LC_Sedimentation_ML-Project_SSI/generate_tfrecord.py --csv_input=/content/drive/MyDrive/Find_LC_Sedimentation_ML-Project_SSI/images/test_labels.csv --image_dir=/content/drive/MyDrive/Find_LC_Sedimentation_ML-Project_SSI/images/test --output_path=test.record"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_W_8L24c4Sk"
      },
      "source": [
        "train_record_path = '/content/train.record'\n",
        "test_record_path = '/content/test.record'\n",
        "labelmap_path = '/content/drive/MyDrive/Find_LC_Sedimentation_ML-Project_SSI/labelmap.pbtxt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK79i98YSY8a"
      },
      "source": [
        "## Configuring training\n",
        "\n",
        "Now that the data is ready it's time to create a training configuration. The OD API supports lots of models, each with its own config file. In this notebook I'm making use of EfficientDet, but you can replace it with any model available in the [Tensorflow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Axko9Jd0hEI3"
      },
      "source": [
        "batch_size = 16\n",
        "num_steps = 8000\n",
        "num_eval_steps = 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RNI68K_dyzX"
      },
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n",
        "!tar -xf efficientdet_d0_coco17_tpu-32.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKENdH3TfhGb"
      },
      "source": [
        "fine_tune_checkpoint = 'efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzQ84qIQelJB"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config\n",
        "\n",
        "base_config_path = 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3ehVTRgesxS"
      },
      "source": [
        "# edit configuration file (from https://colab.research.google.com/drive/1sLqFKVV94wm-lglFq_0kGo2ciM0kecWD)\n",
        "\n",
        "import re\n",
        "\n",
        "with open(base_config_path) as f:\n",
        "    config = f.read()\n",
        "\n",
        "with open('model_config.config', 'w') as f:\n",
        "  \n",
        "  # Set labelmap path\n",
        "  config = re.sub('label_map_path: \".*?\"', \n",
        "             'label_map_path: \"{}\"'.format(labelmap_path), config)\n",
        "  \n",
        "  # Set fine_tune_checkpoint path\n",
        "  config = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "                  'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), config)\n",
        "  \n",
        "  # Set train tf-record file path\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', \n",
        "                  'input_path: \"{}\"'.format(train_record_path), config)\n",
        "  \n",
        "  # Set test tf-record file path\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', \n",
        "                  'input_path: \"{}\"'.format(test_record_path), config)\n",
        "  \n",
        "  # Set number of classes.\n",
        "  config = re.sub('num_classes: [0-9]+',\n",
        "                  'num_classes: {}'.format(1), config)\n",
        "  \n",
        "  # Set batch size\n",
        "  config = re.sub('batch_size: [0-9]+',\n",
        "                  'batch_size: {}'.format(batch_size), config)\n",
        "  \n",
        "  # Set training steps\n",
        "  config = re.sub('num_steps: [0-9]+',\n",
        "                  'num_steps: {}'.format(num_steps), config)\n",
        "  \n",
        "  # Set fine-tune checkpoint type to detection\n",
        "  config = re.sub('fine_tune_checkpoint_type: \"classification\"', \n",
        "             'fine_tune_checkpoint_type: \"{}\"'.format('detection'), config)\n",
        "  \n",
        "  f.write(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmtrS5dihpS_"
      },
      "source": [
        "%cat model_config.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRTBSsYthwxG"
      },
      "source": [
        "model_dir = 'training/'\n",
        "pipeline_config_path = 'model_config.config'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv0sbQlciKWA"
      },
      "source": [
        "## Train detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2zxx5AXiNNK"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_config_path} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --sample_1_of_n_eval_examples=1 \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh2FRsoLQepT"
      },
      "source": [
        "%reload_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK8amcT_wgVb"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '/content/training/train'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3GNLS4ywstA"
      },
      "source": [
        "## Export model inference graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcvbNjcZw2er"
      },
      "source": [
        "output_directory = 'inference_graph'\n",
        "\n",
        "!python /content/models/research/object_detection/exporter_main_v2.py \\\n",
        "    --trained_checkpoint_dir {model_dir} \\\n",
        "    --output_directory {output_directory} \\\n",
        "    --pipeline_config_path {pipeline_config_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcWVXuGAxeZ4"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(f'/content/{output_directory}/saved_model/saved_model.pb') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tGVwzpLxvSv"
      },
      "source": [
        "## Test trained model on test images\n",
        "\n",
        "based on [Object Detection API Demo](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb) and [Inference from saved model tf2 colab](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/inference_from_saved_model_tf2_colab.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp4wlWrhxyJL"
      },
      "source": [
        "import io\n",
        "import os\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import six\n",
        "import time\n",
        "import glob\n",
        "from IPython.display import display\n",
        "\n",
        "from six import BytesIO\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEaYWo8WyLS2"
      },
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: a file path (this can be local or on colossus)\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxWU7K_oyVwq"
      },
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(labelmap_path, use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkMddTneyesG"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = tf.saved_model.load(f'/content/{output_directory}/saved_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxAf3XJBzLHq"
      },
      "source": [
        "def run_inference_for_single_image(model, image):\n",
        "  image = np.asarray(image)\n",
        "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "  input_tensor = input_tensor[tf.newaxis,...]\n",
        "\n",
        "  # Run inference\n",
        "  model_fn = model.signatures['serving_default']\n",
        "  output_dict = model_fn(input_tensor)\n",
        "\n",
        "  # All outputs are batches tensors.\n",
        "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "  # We're only interested in the first num_detections.\n",
        "  num_detections = int(output_dict.pop('num_detections'))\n",
        "  output_dict = {key:value[0, :num_detections].numpy() \n",
        "                 for key,value in output_dict.items()}\n",
        "  output_dict['num_detections'] = num_detections\n",
        "\n",
        "  # detection_classes should be ints.\n",
        "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
        "   \n",
        "  # Handle models with masks:\n",
        "  if 'detection_masks' in output_dict:\n",
        "    # Reframe the the bbox mask to the image size.\n",
        "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
        "               image.shape[0], image.shape[1])      \n",
        "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
        "                                       tf.uint8)\n",
        "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "    \n",
        "  return output_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEX-m3P1yp4y"
      },
      "source": [
        "for image_path in glob.glob('/content/drive/MyDrive/Find_LC_Sedimentation_ML-Project_SSI/images/test/*.jpg'):\n",
        "  image_np = load_image_into_numpy_array(image_path)\n",
        "  output_dict = run_inference_for_single_image(model, image_np)\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=8)\n",
        "  display(Image.fromarray(image_np))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}